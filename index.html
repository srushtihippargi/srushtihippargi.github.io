<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Srushti Hippargi</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha512-pVhYlf8b6+1EJgqD+qndZvjURC1EpD4JYkkkE0AqvjQn7wr3Ym1zOzEV2ZrjogZFl1Ff7C3R5yW9yG+fNE/w5w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <style>
        /* ---- Base ---- */
        *,*::before,*::after{box-sizing:border-box;}
        body{margin:0;font-family:"Segoe UI",Helvetica,Arial,sans-serif;color:#222;line-height:1.6;background:#fff;}
        a{color:#004aad;text-decoration:none;}
        a:hover{text-decoration:underline;}

        /* ---- Header ---- */
        header{width:100%;background:#f2f2f2;border-bottom:1px solid #e7e7e7;}
        .header-inner{max-width:1000px;margin:0 auto;padding:10px 20px;display:flex;align-items:center;justify-content:space-between;}
        header h1{margin:0;font-size:1.6rem;font-weight:600;color:#666;}
        .nav-links{list-style:none;margin:0;padding:0;display:flex;gap:24px;font-weight:500;font-size:0.85rem;}
        .nav-links li a{color:#888;transition:opacity 0.2s ease;}
        .nav-links li a:hover{opacity:0.7;}

        /* ---- Main Content Grid ---- */
        main{max-width:1000px;margin:0 auto;padding:40px 20px 60px;color:#222;}

        /* About section layout */
        .about-wrapper{display:flex;gap:40px;align-items:flex-start;}
        .about-photo figure{margin:0;}
        .about-photo img{width:220px;height:220px;border-radius:10px;object-fit:cover;display:block;}
        .photo-caption p{margin:3px 0;text-align:center;font-size:0.9rem;font-weight:400;color:#777;}
        .about-content{flex:1;}

        /* Section divider + titles */
        .section-divider{border:none;height:1px;width:100%;margin:50px 0 25px;background:linear-gradient(to right,rgba(0,0,0,0),rgba(0,0,0,0.35),rgba(0,0,0,0));}
        h2{margin:0 0 20px;color:#444;font-size:1.6rem;font-weight:600;}

        /* ---- Research Item ---- */
        .research-item{display:flex;gap:40px;align-items:flex-start;margin-bottom:45px;}
        .research-images img{width:360px;height:260px;border-radius:4px;margin-bottom:12px;display:block;border: 2px solid #ccc; } 
/*         .research-images img:hover {transform: scale(1.02);} */
        .research-desc h3{margin:0 0 6px;font-size:1.05rem;font-weight:700;color:#222;}
        .research-desc p{margin:0 0 12px;font-size:0.9rem;}

        .project-item { display: flex; flex-direction: row; gap: 40px; align-items: flex-start; margin-bottom: 60px; flex-wrap: nowrap; } 
        .project-images { flex-shrink: 0; display: flex; flex-direction: column; gap: 12px; } 
        .project-images img { width: 360px; height: 160px; border-radius: 6px; display: block;border: 2px solid #ccc; } 
/*         .project-images img:hover {transform: scale(1.02);} #ccc; padding: 4px;background-color: #fafafa;box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);transition: transform 0.2s ease;*/
        .project-desc { flex: 1; } 
        .project-desc h3 { margin: 0 0 10px; font-size: 1.2rem; font-weight: 700; color: #222; } 
        .project-desc p { margin: 0 0 12px; font-size: 0.95rem; }



        /* ---- Education rows ---- */
        .edu-row{display:flex;align-items:center;margin-bottom:9px;}
        .edu-row img{width:40px;margin-right:10px;}
        .edu-row span{display:block;line-height:1;}


        /* ---- Contact Icons ---- */
        .contact-icons {display: flex;gap: 20px;padding-top: 10px;margin-top: 10px;
        }
        .contact-icons a {display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 48px;
            height: 48px;
            font-size: 22px;
            color: #004aad;
            background-color: #f0f0f0;
            border-radius: 50%;
            text-decoration: none;
            box-shadow: 0 2px 6px rgba(0,0,0,0.1);
            transition: background 0.3s, transform 0.2s;
        }
        .contact-icons a:hover {
            background-color: #004aad;
            color: white;
            transform: translateY(-2px);
        }

        /* ---- Responsiveness ---- */
        @media(max-width:768px){
            .header-inner{flex-direction:column;gap:10px;}
            main{padding:30px 16px 50px;}
            .about-wrapper,.research-item{flex-direction:column;gap:24px;}
            .research-images img{width:100%;}
        }
    </style>
</head>
<body>

<header>
    <div class="header-inner">
        <h1>Srushti Hippargi</h1>
        <ul class="nav-links">
            <li><a href="#about">About</a></li>
            <li><a href="#research">Research</a></li>
            <li><a href="#projects">Projects</a></li>
            <li><a href="#education">Education</a></li>
            <li><a href="assets/pdf/Srushti_Hippargi_CV.pdf" target="_blank">CV</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
    </div>
</header>

<main>
    <!-- About Section -->
    <h2 id="about">About</h2>
    <div class="about-wrapper">
        <div class="about-photo">
            <figure>
                <img src="images/new_photo.png" alt="Srushti Hippargi portrait" />
                <figcaption class="photo-caption">
                    <p>Srushti Hippargi</p>
                    <p>Master's Student</p>
                    <p><a href="https://umich.edu/" target="_blank">University of Michigan, Ann Arbor</a></p>
<!--                     <p><a href="mailto:shipparg@umich.edu">email: shipparg@umich.edu</a></p> -->
                </figcaption>
            </figure>
        </div>
        <div class="about-content">
            <p>
                I am a Master’s student at the <a href="https://www.engin.umich.edu/">University of Michigan, Ann Arbor</a>, specializing in Robotics and Autonomous Vehicles. I completed my undergraduate degree in Mechanical Engineering at <a href="https://witsolapur.org/">Walchand Institute of Technology (WIT), Solapur University, India</a>.
            </p>
            <p>
                My research interests lie in exploring how learning-based methods—particularly in computer vision, deep learning, and language models—can bridge the gap between perception, SLAM, and navigation to help robots and autonomous systems better understand and interact with complex environments. I’m especially excited by questions like: How can a robot remember and reason about what it has seen? How can learned representations improve localization and mapping in dynamic settings? How can semantic knowledge be aligned with physical space to guide decision-making and actions?

            </p>
            <p>
                I’ve worked on projects involving scene understanding, semantic mapping, 3D reconstruction, and uncertainty modeling. In addition, I have experience with state estimation, motion planning and navigation, and optimization techniques for autonomous systems. Currently, I am involved in research at the Computational Autonomy and Robotics Laboratory (CURLY Lab) of <a href="https://robotics.umich.edu/people/faculty/maani-ghaffari/">Professor Maani Ghaffari</a>, where my work focuses on Scene Graph‑Based Vision‑Language Navigation and Temporally Fused Scene Completion
            </p>
             <p><a href="mailto:shipparg@umich.edu">Email</a> | <a href="https://github.com/srushtihippargi">GitHub</a> | <a href="https://www.linkedin.com/in/srushtihippargi/">LinkedIn</a></p>
        </div>
    </div>

    <!-- Research Section -->
    <hr class="section-divider" />
    <h2 id="research">Research</h2>

    <div class="research-item">
        <div class="research-images">
<!--             <img src="we/1/ssc.png" alt="Scene completion visualization – depth map" /> -->
            <img src="we/1/output1.gif" alt="Scene completion visualization – textured result" />
        </div>
        <div class="research-desc">
            <h3>BEV‑Temporal Fusion based Scene Completion on LiDAR data</h3>
            <p><em><a href="https://curly.engin.umich.edu/">Research Assistant, CURLY Lab (May&nbsp;2024&nbsp;–Present&nbsp;)</a></em></p>
            <p>Integrated FuseNet LSTM/UNet architectures into LMSCNet for BEV‑based temporal fusion. Developed local 3D mapping with a voxel‑based sliding‑window approach for dynamic scene completion and incorporated uncertainty and confidence into the model.</p>
        </div>
    </div>

    <div class="research-item">
        <div class="research-images">
<!--             <img src="we/2/gs1.png" alt="Scene completion visualization – depth map" /> -->
            <img src="we/2/mcity_dyn_gs.gif" alt="Scene completion visualization – textured result" />
        </div>
        <div class="research-desc">
            <h3>Dynamic 3D Reconstruction with Gaussian Splatting and Scene Flow Estimation</h3>
            <p><em><a href="https://www.roahmlab.com/">Robotics Intern, ROAHM Lab (May&nbsp;2024&nbsp;–&nbsp;2025)</a></em></p>
            <p>Developed a dynamic Gazebo simulation with multi-view cameras and 3D LiDAR, visualized in ROS2 and RViz. Performed 3D/4D Gaussian splatting for warehouse reconstruction, optimized sensor placement, and integrated rigid scene flow for dynamic consistency.</p>
        </div>
    </div>

    <div class="research-item">
        <div class="research-images">
            <img src="we/3/mcity.gif" alt="Scene completion visualization – depth map" />
<!--             <img src="we/3/mcity2.png" alt="Scene completion visualization – textured result" /> -->
        </div>
        <div class="research-desc">
            <h3>Digital Twin Creation of MCity using Gaussian Splatting and Multi-View Capture</h3>
            <p><em><a href="https://www.capoom.com/">Reserch Cohort, Capoom, Techlab at Mcity (Jan&nbsp;2024&nbsp;–August&nbsp;2024)</a></em></p>
            <p>Designed a parallel‑capture pipeline with eight calibrated Lucid cameras on a Mach‑E, synchronizing 30 Hz frames. Leveraged GPU‑accelerated Gaussian Splatting to reconstruct a centimeter‑accurate 3D digital twin, slashing build time 4× versus COLMAP baselines.</p>
<!--             Designed a parallel‑capture pipeline with eight calibrated Lucid cameras on a Mach‑E, synchronizing 30 Hz frames via custom Python scripts to acquire dense, time‑aligned imagery of the 32‑acre MCity track. Leveraged GPU‑accelerated Gaussian Splatting to reconstruct a centimeter‑accurate 3D digital twin, slashing build time 4× versus COLMAP baselines and enabling rapid prototyping -->
        </div>
    </div>

    <!-- Projects Section -->
    <hr class="section-divider" />
    <h2 id="projects">Projects</h2>

    <div class="project-item">
        <div class="project-images">
            <img src="p/ground.gif" alt="Faster R-CNN detection output" />
        </div>
        <div class="project-desc">
            <h3>Reinforcement Learning Based Adaptive Grasping</h3>
            <p><a href="https://github.com/srushtihippargi/DeepRob_Ungraspable">Code | <a href="https://deeprob.org/w24/reports/grasping-ungraspable/">Project Page</a></p>
            <p>Developed and trained distinct RL-based policies for ground, side, and unoccluded grasps in MuJoCo, achieving a 100% simulated success rate across all occlusion types. Evaluated two policy selection strategies—box-size heuristics and Q-maximization—demonstrating robust grasp execution under partial visibility conditions.</p>
        </div>
    </div>

     <div class="project-item">
        <div class="project-images">
            <img src="p/gcnn.png" alt="Faster R-CNN detection output" />
        </div>
        <div class="project-desc">
            <h3>GCNN-based Deep Loop Closure Detection for SLAM</h3>
            <p><a href="https://github.com/srushtihippargi/LCDNet-GCNN">Code</a></p>
            <p>Extended the LCDNet architecture by integrating Cyclic Group Convolutional Neural Networks (GCNNs) to enable rotation-invariant loop closure detection. Evaluated on symmetric scenes in KITTI-360, the method improved translational and rotational accuracy.</p>
        </div>
    </div>

     <div class="project-item">
        <div class="project-images">
            <img src="p/ana.png" alt="Faster R-CNN detection output" />
        </div>
        <div class="project-desc">
            <h3>Anytime Path Planning for time-Critical Robot Navigation Using ANA*</h3>
            <p><a href="https://github.com/srushtihippargi/Search-Based-Planning">Code</a></p>
            <p>Implemented and compared A* and ANA* algorithms for 8-connected grid-based robotic navigation with orientation and obstacle handling. Demonstrated that ANA* rapidly generates feasible paths and refines them over time, making it ideal for real-time, time-constrained applications such as doorway traversal with PR2.</p>
        </div>
    </div>

    
    <div class="project-item">
        <div class="project-images">
            <img src="p/pose.png" alt="Faster R-CNN detection output" />
        </div>
        <div class="project-desc">
            <h3>PoseCNN: Object Pose Estimation</h3>
            <p><a href="https://github.com/srushtihippargi/PoseCNN">Code</a></p>
            <p>Implemented PoseCNN using a VGG16-based backbone to estimate 6-DOF object poses with segmentation, translation, and rotation outputs. Integrated RoI pooling, quaternion regression, and a Hough Voting layer to achieve pose accuracy within 5 degrees.</p>
        </div>
    </div>

    <div class="project-item">
        <div class="project-images">
            <img src="p/fast.png" alt="Faster R-CNN detection output" />
        </div>
        <div class="project-desc">
            <h3>Faster R-CNN: Two-Stage Object Detection</h3>
            <p><a href="https://github.com/srushtihippargi/FasterR-CNN">Code</a></p>
            <p>Built a two-stage object detector from the ground up, implementing a Region Proposal Network (RPN) for generating candidate regions and a RoI head for classification and box refinement. Achieved 25% mAP at 70% IoU, demonstrating effective localization and recognition capabilities.</p>
        </div>
    </div>

    <div class="project-item">
        <div class="project-images">
            <img src="p/robust.png" alt="Faster R-CNN detection output" />
        </div>
        <div class="project-desc">
            <h3>Robustness Analysis of Centralized Multi-Robot SLAM</h3>
            <p><a href="https://github.com/srushtihippargi/Robustness-Comparison">Code</a></p>
            <p>Extended the JORB-SLAM framework to support three autonomous agents and evaluated its resilience to data loss using Chamfer and Hausdorff distances on the KITTI dataset. Developed a systematic seeded-error injection mechanism to simulate real-world SLAM failures and benchmark robustness across ORB-SLAM2, JORB-SLAM, and Collaborative ORB-SLAM2 under increasing noise levels.</p>
        </div>
    </div>


    <!-- Education Section -->
    <section class="container" id="education">
        <hr class="section-divider" />
        <h2 class="col-12 px-0 mb-0">Education</h2>

        <div class="edu-row">
            <img src="images/um.png" alt="UMich Logo" />
            <div>
                <span style="font-size:14px;">M.S. Automotive Engineering (Robotics &amp; Autonomous Vehicles), University of Michigan, Ann Arbor</span>
                <span style="font-size:12px;">Aug&nbsp;2023&nbsp;–&nbsp;Apr&nbsp;2025</span>
            </div>
        </div>

        <div class="edu-row">
            <img src="images/wit.png" alt="WIT Logo" />
            <div>
                <span style="font-size:14px;">B.E. Mechanical Engineering, Walchand Institute of Technology, Solapur University (India)</span>
                <span style="font-size:12px;">Aug&nbsp;2016&nbsp;–&nbsp;Apr&nbsp;2020</span>
            </div>
        </div>
    </section>

    <!-- Contact Section -->


     <!-- Contact Section -->
    <hr class="section-divider" />
    <h2 id="contact">Contact</h2>
    <div class="contact-icons">
      <a href="mailto:shipparg@umich.edu" title="Email"><i class="fa-solid fa-envelope"></i></a>
      <a href="https://github.com/srushtihippargi" target="_blank" title="GitHub"><i class="fa-brands fa-github"></i></a>
      <a href="https://www.linkedin.com/in/srushtihippargi" target="_blank" title="LinkedIn"><i class="fa-brands fa-linkedin-in"></i></a>
    </div>

<!--     <hr class="section-divider" /> -->
<!--     <h2 id="contact">Contact</h2> -->
<!--     <p>Feel free to reach out via <a href="mailto:shipparg@umich.edu">email</a> or connect with me on <a href="https://www.linkedin.com/in/srushtihippargi" target="_blank">LinkedIn</a>.</p> -->
</main>

</body>
</html>
